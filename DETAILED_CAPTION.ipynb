{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download the model checkpoint and configure it so that you can fine-tune it later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers flash_attn timm einops peft\n",
    "!pip install -q roboflow git+https://github.com/roboflow/supervision.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Imports\n",
    "import cv2\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import torch\n",
    "import html\n",
    "import base64\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "\n",
    "from google.colab import userdata\n",
    "from IPython.core.display import display, HTML\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoProcessor,\n",
    "    get_scheduler\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict, Any, Tuple, Generator\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from PIL import Image\n",
    "from roboflow import Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT = \"microsoft/Florence-2-base-ft\"\n",
    "REVISION = 'refs/pr/6'\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(CHECKPOINT, trust_remote_code=True, revision=REVISION).to(DEVICE)\n",
    "processor = AutoProcessor.from_pretrained(CHECKPOINT, trust_remote_code=True, revision=REVISION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"<DETAILED_CAPTION>\"\n",
    "text = \"<DETAILED_CAPTION>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('/content/test_video.mp4')\n",
    "\n",
    "frame_number = 1\n",
    "frame_and_caption = {}  # Initialize dictionary to store frame numbers and captions\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break  # Exit the loop if no more frames are available\n",
    "\n",
    "    \n",
    "    frame_count += 1\n",
    "    if frame_count % 10 == 0:\n",
    "     \n",
    "        inputs = processor(text=text, images=frame, return_tensors=\"pt\").to(DEVICE)\n",
    "        generated_ids = model.generate(\n",
    "              input_ids=inputs[\"input_ids\"],\n",
    "              pixel_values=inputs[\"pixel_values\"],\n",
    "              max_new_tokens=1024,\n",
    "              num_beams=3\n",
    "          )\n",
    "        \n",
    "        generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
    "          \n",
    "          # Assuming 'task' and 'image_size' are defined earlier\n",
    "        response = processor.post_process_generation(generated_text, task=task, image_size=(frame.shape[1], frame.shape[0]))\n",
    "          \n",
    "          # Store the generated caption for the current frame\n",
    "        if '<DETAILED_CAPTION>' in response:\n",
    "              frame_and_caption[frame_number] = response['<DETAILED_CAPTION>']\n",
    "\n",
    "        frame_number += 1\n",
    "        \n",
    "    \n",
    "    # Break the loop on pressing 'Esc'\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "      break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the stored frame and caption data\n",
    "print(frame_and_caption)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
